\include{./../latex/notes_style.tex}

\setcounter{unit}{2}
\setcounter{section}{0}


\begin{document}

\title{Unit 2: Expectation and variance, Normal distribution and CLT}
\author{Ethan Levien}
\maketitle
\tableofcontents



\section*{Introduction}


In this section we introduce \dfn{expectation}, an operation which takes a random variable and produces a deterministic quantity. The expectation of a random variable can be approximated with \dfn{sample averages} and from them we can infer properties of the model (like parameters). Much of statistics relies on the fact that sample averages approximate expectations, and understanding how well these approximations work is a central goal of statistics. This will motivate us to study the probability distribution of sums of random variables, which leads to the \dfn{CLT} and the \dfn{Normal distribution.} If there is time, we will also learn about \dfn{log normal distributions}, which are a better model for many real world random variables, but can easily by mapped to normal random variables. 





\section{Expectation, variance and standard deviation}




\subsection{Sample averages and expectation}
\sectionrefs{ \cite[Ch. 3]{evans}}
 Usually it is difficult to obtain the full distribution of a random variable from data and it may not even be that relevant for the questions we are asking. Instead, we would like to summarize properties of a random variable by looking at averages.  In other cases, we have a good idea what the type of distribution is, but there are unknown parameters which can be estimated by averages.  
 
 You are probably familiar with the \dfn{sample mean}, \dfn{sample average}, or \dfn{empirical average}. 
If $Y_1,Y_2,\dots,Y_n$ are iid samples of $Y$, the sample mean is defined as
\begin{equation*}
\overline{Y} = \frac{1}{n}\sum_{i=1}^nY_i
\end{equation*}
Sometimes the notation $\langle \cdot \rangle$ is used. 
More generally, we might look at the average of some function of a random variable 
\begin{equation*}
\overline{g(Y)} = \frac{1}{n}\sum_{i=1}^nf(Y_i)
\end{equation*}
(Remember, a function of a random variable is just another random variable, so there is nothing too deep here). 
If we take the function to be 
\begin{equation}
g(y) =1_A(y) =  \left\{\begin{array}{lr} 
1 & \text{if }y \in A\\
0 & \text{if }y \in A
\end{array}\right.
\end{equation}
Then we can connect the idea of a sample average to estimates of probabilities via
\begin{equation}
\overline{g(Y)} = \frac{N(y \in A)}{n} \approx P(\{Y \in A\})
\end{equation}
Any quantity we compute from data is in some way a sample average, so a great deal of statistics is about understanding the behavior of sample averages. 

Now we introduce the idea of \dfn{expectation}. I like to think of expectation as the mathematical idealization of a sample average, just as probabilities are mathematical idealizations of long-run frequencies\footnote{This is at least the frequentist interpretation. We can also interpret them as measures of belief. More on that in Unit 6 and 7}.   Suppose each $Y_i$ are iid random variables with each having sample space $Y$. If $n$ is large, then of course the fraction of samples for which $Y_i= y$ will be $\approx P(\{Y_1=y\})$. We can express the sample average in terms of the probabilities via
 \begin{equation*}
\overline{Y} =  \frac{1}{n}\sum_{i}Y_i = \frac{1}{n} \sum_{y \in S} y N(Y=y) =\sum_{y \in S} y \frac{N(Y=y) }{n}\approx  \sum_{y\in S} y P(Y=y).
\end{equation*}
The second equality just came from putting the samples in groups according to their value of $y$. 
The expression on the right is the definition of the mean, or \dfn{expectation}, and is denoted
\begin{equation}
\E[Y] = \sum_{y=1}^m y P(Y=y)
\end{equation}
  To summarize what we saw above (and should be intuitively clear) 
 \begin{equation}\label{eq:EappoverY}
 E[Y] \approx \overline{Y}
 \end{equation}
 Sometimes we use $\E$ instead of $E$ to distinguish it from other variables names $E$, but I will try not to use $E$ for other things. 
If we have a function $g:S \to S'$ from the sample space to some other space $S'$, then $g(Y)$ is simply a new random variable with sample space $S'$, but we don't usually need to find the distribution of $X = g(Y)$ to compute expectations, since this can be written  
\begin{equation}\label{eq:Efy}
E[X] = E[g(Y)] = \sum_{y\in S} g(y) P(Y=y). 
\end{equation}
The nice thing here is that we can use the probability distribution for $Y$ to compute the expectation of $X$, which in some cases may be simpler (this is the case for variance below). 

 It is important to understand that, just like probabilities, the expectation is an operation which takes a random variable to a deterministic number. The sample average is the approximate version of this. I like to think of expectations and sample averages as living in ``math world'' and ''data world'' respectively. After discussion variance, standard deviation and CV, Section \ref{sec:llnclt} will take you on a deeper dive into this connection, which is made precise by the LLN and CLT. 


\begin{example}[Expectation of a discrete random variable]
Let $Y$ be a random variable taking values in $\{1,2,3\}$ with probabilities
\[
P(Y=1)=\tfrac{1}{2}, \quad P(Y=2)=\tfrac{1}{3}, \quad P(Y=3)=\tfrac{1}{6}.
\]

\noindent
\underline{Question}: What is $E[Y]$?\\

\noindent
\underline{Solution}: By definition,
\begin{align*}
E[Y] &= \sum_{y=1}^3 y P(Y=y) \\
     &= 1\cdot \tfrac{1}{2} + 2\cdot \tfrac{1}{3} + 3\cdot \tfrac{1}{6} \\
     &= \tfrac{1}{2} + \tfrac{2}{3} + \tfrac{1}{2} \\
     &= \tfrac{5}{3}.
\end{align*}
So the expected value of $Y$ is $E[Y] = \tfrac{5}{3}$. 

\noindent
\underline{Python exercise}: Write code that generates a dataframe with $n$ simulated values of $Y$, computes the sample mean, and plots the sample mean as a function of $n$. Compare your results with the theoretical expectation $E[Y]=5/3$. 

\begin{lstlisting}[language=Python]
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Define the probability distribution
values = [1, 2, 3]
probs = [1/2, 1/3, 1/6]

# Number of samples to generate
Nmax = 5000

# Draw samples from the distribution
samples = np.random.choice(values, size=Nmax, p=probs)

# Store in a dataframe
df = pd.DataFrame({"Y": samples})

# Compute running sample mean
sample_means = df["Y"].expanding().mean()

# Plot sample mean vs n
plt.figure(figsize=(6,4))
plt.plot(sample_means, label="Sample mean")
plt.axhline(5/3, color="red", linestyle="--", label="Theoretical $E[Y]=5/3$")
plt.xlabel("n (sample size)")
plt.ylabel("Sample mean")
plt.legend()
plt.title("Convergence of sample mean to expectation")
plt.show()
\end{lstlisting}
\end{example}

\subsection{Measuring variation}
One of the most important expectations is the \dfn{variance}, which measures the typical distance from the mean. This is defined as
\begin{equation*}
{\rm var}(Y) = E[(Y-E[Y])^2]
\end{equation*}
which you should comes from taking $f(Y) = (Y-E[Y])^2$ in Eq. \ref{eq:Efy}. 
Another way to write this is 
\begin{equation*}
 {\rm var}(Y) = E[Y^2] - 2(E[Y])^2 + E[Y]^2 = E[Y^2]-(E[Y])^2
\end{equation*}

\begin{example}[Mean and variance of Bernoulli random variable]
Let $Y$ be a Bernoulli random variable with parameter $q$. We will use the convention that $Y=1$ with probability $q$.\\


\noindent
\underline{Question}: What is $E[Y]$ and ${\rm var}(Y)$?\\

\noindent
\underline{Solution}: Using the definitions above
\begin{equation*}
E[Y] = P(Y=0)\times 0 + P(Y=1)\times 1 = q
\end{equation*}
similarly you should be able to see that ${\rm var}(Y) = q(1-q)$. Try testing this formula with Python (this is one of the exercises). 
\end{example}

Based on this example, we can see that to estimate $q$ we can use $\hat{q} = \bar{Y}$ (as expected). Here I'm defining $\hat{q}$ as shorthand for an estimator of $q$. 


To measure ``how much variation'' there is in a random variable, we need to compare the variance to the mean. However, there is a problem with doing this directly: the variance has different units than the mean. For example, say we are looking at human height. If the mean height is about $170 \,\text{cm}$, then the variance might be something like $100 \,\text{cm}^2$. This is hard to interpret because the mean is measured in centimeters, while the variance is in squared centimeters. To make the comparison meaningful, we first take the square root of the variance to obtain the \dfn{standard deviation}, which brings the measure of spread back into the same units as the mean (in this case, centimeters). Now we can meaningfully say that the spread around the mean height is about $10 \,\text{cm}$.  

But even the standard deviation is not enough by itself when we want to compare variability across different contexts. Suppose we measure the weights of the same individuals, where the mean is around $70 \,\text{kg}$ and the standard deviation is $10 \,\text{kg}$. The ``10'' here is not directly comparable to the ``10'' cm in height, because the scales of measurement are different. What matters is not the absolute size of the variation, but its size \emph{relative to the mean}.  

This leads us to the \dfn{coefficient of variation (CV)}, defined as 
\begin{equation}
\text{CV} = \frac{\sigma}{\mu},
\end{equation}
where $\sigma$ is the standard deviation and $\mu$ is the mean. The CV is unitless and therefore allows for comparisons across variables measured in different units or across distributions with very different scales. For example, a CV of $0.06$ in human height ($10/170$) indicates less relative variability than a CV of $0.14$ in weight ($10/70$).  

Thus, the CV is the correct measure of variation when our goal is to compare variability across different contexts, because it removes dependence on units and scale while still preserving the intuitive meaning of variation as ``spread relative to the average.''  





\subsection{Conditional expectation}
\sectionrefs{\cite[Ch. 1 Sec. 2 and Ch. 2.1]{evans}}

 We define the conditional expectation  \cite[Definition 3.5.1]{evans} as the expectation of the conditional variable; that is, 
\begin{equation*}
E[X|Y=y] = \sum_{x} xP(X|Y=y)
\end{equation*}
With samples
\begin{equation*}
\{(x_1,y_1),\dots,(x_n,y_n)\}
\end{equation*}
we have 
 \begin{equation*}
E[X|Y=y] \approx  \frac{1}{N(Y=y)}\sum_{i=1}^n1_{\{y_i = y\}}x_i
 \end{equation*}
 where $1_{\{y_i = y\}}$ is the \dfn{indicator function}
 \begin{equation*}
 1_{\{y_i = y\}} = \left\{ \begin{array}{cc}
 0 & \text{ if } y_i\ne y\\
  1 & \text{ if } y_i=y
  \end{array}\right.
 \end{equation*}
Don't get too hung up on the notation, put simply: we compute the conditional expectation from a sample average by taking the sample average among samples satisfying a condition. 

 As we already noted, the conditional probabilities can tell us whether two variables are independent. That is, $P(X|Y) = P(X)$ if and only if $X$ and $Y$ are independent. If $X$ and $Y$ are independent, then $E[X|Y=y]= E[X]$ for all $y$ but the converse is false: {\bf it is possible that this is true but $X$ and $Y$ are not independent!} We will say about this later.  




\begin{example}[Computing conditional expectation]
Consider the pair of random variables $(Y_A,Y_B)$ defined by the probability distribution we saw in week 1:
\begin{equation}\label{eq:gene}
P(Y_A,Y_B) = \left\{ \begin{array}{cc}
1/2 & \text{ if }Y_A=0 \text{ and } Y_B = 0\\
1/8 & \text{ if }Y_A=0 \text{ and } Y_B = 1\\
1/8 & \text{ if }Y_A=1 \text{ and } Y_B = 0\\
1/4 & \text{ if }Y_A=1 \text{ and } Y_B = 1\\
\end{array}
 \right.\\
\end{equation}


\noindent
\underline{Question}: Compute $E[Y_A|Y_B=1]$\\

\noindent
\underline{Solution}: We can obtain the conditional distribution of $Y_A$ as 
\begin{equation*}
P(Y_A=1|Y_B = 1) = \frac{P(Y_A=1,Y_B=1)}{P(Y_B=1)} = \frac{1/4}{3/8} = \frac{2}{3}
\end{equation*}
Note that his means $P(Y_A=0|Y_B = 1) = 1/3$ and so the conditional distribution of  $Y_A$ is 
\begin{equation*}
Y_A|(Y_B=1) \sim {\rm Bernoulli}(2/3)
\end{equation*}
which means 
\begin{equation*}
E[Y_A|Y_B=1] = \frac{2}{3}.
\end{equation*}

\end{example}


\begin{example}[Mean of a Geometric random variable via simulation]
Let $X \sim \mathrm{Geometric}(q)$ with support $\{1,2,\dots\}$, i.e.,
\[
P(X=k) = q(1-q)^{k-1},\quad k\in\{1,2,\dots\}.
\]

\noindent
\underline{Question}: Use simulations to confirm that $E[X] = 1/q$.\\

\noindent
\underline{Solution}: 

\begin{lstlisting}[language=Python]
import numpy as np
import matplotlib.pyplot as plt

rng = np.random.default_rng(42)

q = 0.3        # success probability
N = 100_000    # total number of samples

# NumPy's geometric uses support {1,2,...} with P(X=k)=q(1-q)^{k-1}
X = rng.geometric(p=q, size=N)

# Running sample mean
running_mean = np.cumsum(X) / np.arange(1, N+1)

print(f"Theoretical E[X] = {1/q:.6f}")
print(f"Estimated  E[X] = {running_mean[-1]:.6f}")
\end{lstlisting}

Analytically,
\[
E[X] = \sum_{k=1}^\infty k\,q(1-q)^{k-1}
= q \cdot \sum_{k=1}^\infty k r^{\,k-1}\Big|_{r=1-q}
= q \cdot \frac{1}{(1-r)^2}\Big|_{r=1-q}
= \frac{1}{q}.
\]
but you don't need to be able to do this calculation. 


\end{example}

\begin{example}[Computing conditional expectation from data ]
Consider the following data containing children's test scores and some other information. 
\begin{lstlisting}[language=Python]
# Here is some data on children's test scores
url = (
    "https://raw.githubusercontent.com/"
    "avehtari/ROS-Examples/"
    "master/KidIQ/data/kidiq.csv"
)
df = pd.read_csv(url)
df
\end{lstlisting}

Let $Y$ be the test score and $X$ be a binary variable representing whether the mother graduated high school.\\

% Supp
%\begin{align*}
%X &\sim {Bernoulli}(q)\\
%Y|(X=x) &\sim {\mr Normal}(\mu_1 X + \mu_2 (1-x),\sigma)
%\end{align*}

\noindent
\underline{Question}: Compute $E[Y|X=0]$ and $E[Y]$. Do you think $X$ and $Y$ are independent? \\

\noindent
\underline{Solution}: See Python notebook.



\end{example}




  \subsection{Properties of expectation}\label{prop:lin} 
  
Expectation has some important properties. These become particularly relevant when we work with linear regression models, which are defined in terms of conditional expectations. 
  \begin{enumerate}
  \item {\bf Linearity  \cite[Theorem 3.1.2]{evans}:} For two random variables $X$ and $Y$   \begin{equation*}
  E[X+Y] = E[X]+E[Y]
  \end{equation*}
  \begin{proof} We do the proof when the sample spaces $S_X$ and $S_Y$ are discrete: 
  \begin{align*}
  E[X+Y] &= \sum_{y \in S_Y}\sum_{x\in S_X} (x+y)P(X=x,Y=y) \\
  &= \sum_{x \in S_X} \sum_{y \in S_Y} xP(X=x,Y=y)  +  \sum_{x \in S_X} \sum_{y \in S_Y} yP(X=x,Y=y) \\
  &= \sum_{x \in S_X} x\left( \sum_{y \in S_Y}P(X=x,Y=y)  \right)+   \sum_{y \in S_Y} y\left( \sum_{x \in S_X} P(X=x,Y=y)\right) \\
  &= E[X] + E[Y]
  \end{align*}
  \end{proof}
    \item {\bf Multiplication by a constant \cite[Theorem 3.1.2]{evans}:} If $a$ is a constant (meaning it is not random), then 
    \begin{equation*}
      E[aX] =  a E[X]
    \end{equation*}
     \begin{proof}  Left as an exercise. 
     \end{proof}
  \item \label{prop:ind}  {\bf Factoring for independent variables \cite[Theorem 3.1.3]{evans}:} If $X$ and $Y$ are independent, the 
  \begin{equation*}
  E[XY]=E[X]E[Y]
  \end{equation*}
    \begin{proof} Using independence, we have 
    \begin{align*}
     E[XY] &= \sum_{x \in S_X}\sum_{y \in S_Y} xy P(X=x,Y=y)  \\
     &= \sum_{x \in S_X}\sum_{y \in S_Y} xP(X=x)yP(Y=y) \\
     &= \left( \sum_{x \in S_X} xP(X=x)\right)\left( \sum_{y \in S_Y} yP(Y=y)\right)= E[X]E[Y]
    \end{align*}
    \end{proof}
    \item {\bf Tower property \cite[Theorem 3.5.2]{evans}:} Let $X$ and $Y$ be two random variables,  
   \begin{equation*}
   E[E[X|Y]] = E[X]
   \end{equation*}
   where by $E[X|Y]$ we mean the random variable constructed by taking the conditional expectation of $X$ given a random value of $Y$. Another way to define this is to introduce the deterministic function  $f(y) = E[X|Y=y]$ which outputs a number for every value $y \in Y$. Then we define the random variable $E[X|Y] = u(Y)$.  Therefore
   \begin{equation*}
   E[E[X|Y]]  = E[f(Y)] 
   \end{equation*}
   \begin{proof}
   Left as an exercise. 
   \end{proof}
  \end{enumerate}

  
  
\begin{example}[Calculating conditional expectations]
Consider the probability model for a variable $X$
\begin{equation}\label{eq:Xdist_ex}
P(X=x)=
\begin{cases}
\frac{1}{2}, & x=1,\\[2pt]
\frac{1}{8}, & x=2,\\[2pt]
\frac{1}{8}, & x=3,\\[2pt]
\frac{1}{4}, & x=4,
\end{cases}
\end{equation}
and define
\begin{equation}\label{eq:YZ_ex}
Y = X\cdot Z,\qquad Z \sim \mathrm{Geometric}(X/4),
\end{equation}


\noindent
\underline{Question}: Compute $E[Y]$ using the tower property and check your answer using simulations.\\

\noindent
\underline{Solution}:
By the tower property,
\begin{align}
E[Y] &= E\!\left[\,E[Y\mid X]\,\right] \label{eq:tower_start}\\
     &= E\!\left[\,E[XZ\mid X]\,\right]  \\
     &=\sum_{x \in S_X} P(X=x) E[xZ\mid X=x] \label{eq:pull_out}\\
     &=\sum_{x \in S_X} P(X=x)x E[Z| X=x] = \sum_{x \in S_X} P(X=x)x\frac{4}{x}\\
     &= E\!\left[\,X \cdot \frac{4}{X}\,\right] \label{eq:geom_mean}\\
     &= E[\,4\,] \;=\; 4. \label{eq:finalEY}
\end{align}
Hence, regardless of the distribution in \eqref{eq:Xdist_ex}, as long as $Z\sim\mathrm{Geometric}(X/4)$ (with support starting at $1$), we have
\begin{equation}\label{eq:EY_value}
E[Y]=4.
\end{equation}

\begin{lstlisting}[language=Python]
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

rng = np.random.default_rng(2025)

# Distribution of X
x_vals  = np.array([1, 2, 3, 4])
x_probs = np.array([1/2, 1/8, 1/8, 1/4])

def simulate(N):
    # Sample X
    X = rng.choice(x_vals, size=N, p=x_probs)
    # For each X, sample Z ~ Geometric(p=X/4)
    Z = np.array([rng.geometric(p=xi/4) for xi in X])
    Y = X * Z
    return pd.DataFrame({"X": X, "Z": Z, "Y": Y})

# Run simulation
N = 200_000
df = simulate(N)

# Estimate E[Y]
EY_hat = df["Y"].mean()

# Empirical E[E[Y|X]]
EY_given_X_hat = df.groupby("X")["Y"].mean().sort_index()
pX_hat         = df["X"].value_counts(normalize=True).sort_index()
EEY_given_X_hat = (EY_given_X_hat * pX_hat).sum()

print(f"Theoretical E[Y]    = 4.000000")
print(f"Estimated E[Y]      = {EY_hat:.6f}")
print(f"Estimated E[E[Y|X]] = {EEY_given_X_hat:.6f}")
print("\nConditional means E[Y|X=x] (each should be ~4):")
print(EY_given_X_hat)
\end{lstlisting}

\end{example}

%\noindent
%\underline{Solution}:  Let $(X_1,Y_2),\dots,(X_N,Y_N)$ be our samples. We will show that $E[X] = E[E[X|Y]]$. The left hand side is easy to approximate with samples -- just take the mean of the $X$ values. To compute $E[X|Y]$ we need to compute $E[X|Y=y]$ for each $y$. If $N(y)$ is the number of samples such that $Y_i=y$ then 
%\begin{equation*}
%E[X|Y=y] \approx \frac{1}{N(y)}\sum_{\{i:Y_i =y\}}X_i
%\end{equation*}
%The sum is over all the $Y_i$ for which $Y_i=y$. We could also write this sum as $\sum_{i=1}^NX_i1_{Y_i=y}$. 
%This means 
%\begin{equation*}
%E[E[X|Y]] \approx E\left[ \frac{1}{N(y)}\sum_{\{i:Y_i =Y\}}X_i  \right] = \sum_{y \in S_y}P(Y=y)\underbrace{\left(\frac{1}{N(y)}\sum_{\{i:Y_i =y\}}X_i  \right)}_{\approx E[X|Y=y]}
%\end{equation*}
%Now use that $P(Y=y) \approx N(y)/N$, therefore 
%\begin{equation*}
%E[E[X|Y]]  \approx \sum_{y \in S_y}\frac{1}{N(y)}\sum_{\{i:Y_i =y\}}X_i  \frac{N(y)}{N}
%\end{equation*}
%Notice that when we cancel the $N(y)$ terms we just get the usual sample mean of $X$: 
%\begin{equation*}
%E[E[X|Y]]  \approx \frac{1}{N} \sum_{y \in S_y}\sum_{\{i:Y_i =y\}}X_i   =  \frac{1}{N}\sum_{i=1}^NX_i = \overline{X} \approx E[X]
%\end{equation*}

 %\end{example}

% \begin{example}[Binomial distribution in python]
% Let's explore binomial random variables in python. 
% \end{example}
 
\begin{example}[Expectation of binomial]\label{ex:binomial_stats}
Let $Y$ be a binomial random variable. \\
 
 \noindent
\underline{Question:} What are $E[Y]$ and ${\rm var}(Y)$?\\
 
 
  \noindent
\underline{Solution:} 
\begin{equation*}
E[Y] = \sum_{k=1}^N k P(Y=k) =\sum_{k=1}^N k  {N \choose k}q^{k}(1-q)^{N-k} = \cdots. 
\end{equation*}
A much easier way is to use the definition of a Binomial random variable and exceptions 
\begin{align*}
E[Y] &= E\left[\sum_{j=1}^NX_i\right]\\
& \underset{(1)}{=}  \sum_{j=1}^NE\left[X_i\right]  =Nq
\end{align*}
where we are using the fact that averages are additive (property (1)). Similarly, 
\begin{align*}
E[Y^2] &= E\left[\left(\sum_{j=1}^NX_i\right)^2\right] = E\left[\sum_{i=1}^N\sum_{j=1}^NX_iX_j\right] \\
&\underset{(1)}{=}  \sum_{i=1}^N\sum_{j=1}^NE[X_iX_j]\underset{(3)}{=} \sum_{i=1}^N\sum_{j \ne i}^Nq^2 +  Nq(1-q) + Nq^2\\
&= N(N-1)q^2 + Nq(1-q)  +  Nq^2 = Nq(1-q)  + N^2q^2
\end{align*}
Therefore 
\begin{equation*}
{\rm var}(Y) =E[Y^2]-E[Y]^2 =  Nq(1-q)
\end{equation*}
\end{example}
 
To summarize what we learned in Example \ref{ex:binomial_stats}
\begin{equation}\label{eq:binomial_meanvar}
E[Y] = qN \quad\quad{\rm var}(Y) = Nq(1-q). 
\end{equation}


 
 The important observation that the mean grows much faster with $N$ than the variance is also captured by the coefficient of variation: 
\begin{equation*}
{\rm CV} = \frac{\sqrt{{\rm var}(Y)}}{E[Y]} = \sqrt{\frac{(1-q)}{q} \frac{1}{N}}. 
\end{equation*}
The idea is that we are measuring the variation \emph{relative} to the average. This is relevant for many applications where we only care about the relative deviations. 

%\item 
% Binomial samples can be generated in numpy with
% \begin{Verbatim}
%y = np.random.binomial(n,p,n_samples)
% \end{Verbatim}
 %\item Often we are interested not in $Y$, but the fraction $\phi = Y/N$. For example, we might be interested in the vote share in an election. 
 
 \begin{example}[Election modeling]
 Consider a model of votes in an election involving two candidate. Let $q$ be the fraction of people in the population who support candidate one and suppose $N$ people vote at the election (you can assume $N$ is much less than the total number of people in the population, as voter turnout is low). Then the number of people, $M$, who vote for the first candidate can be modeled as 
\begin{equation*}
M \sim {\rm Binomial}(N,q)
\end{equation*}
Think about the assumption we are making when we use this model. \\

 \noindent
\underline{Question:} Suppose there is a city in which a fraction $q = 0.51$ of people support a candidate for city council. If $N=1000$ people turnout for the election, what is the chance that the actual vote share, $\phi = M/N$, differs from the actual fraction of support throughout the population by more than $1\%$?\\

 \noindent
\underline{Solution:} 

\begin{lstlisting}[language=Python]
import numpy as np
import matplotlib.pyplot as plt

# Parameters
q = 0.51       # true population support
N = 1000       # number of voters
delta = 0.01   # tolerance for deviation in vote share
trials = 200_000  # Monte Carlo repetitions

rng = np.random.default_rng(123)

# --- Monte Carlo estimation ---
# Draw M ~ Binomial(N, q) many times, compute phi = M/N, estimate P(|phi - q| > delta)
M_samples = rng.binomial(n=N, p=q, size=trials)
phi = M_samples / N
prob_est = np.mean(np.abs(phi - q) > delta)

print(f"Monte Carlo estimate P(|phi - {q}| > {delta}) = {prob_est:.6f} "
      f"(N={N}, trials={trials})")
\end{lstlisting}
\end{example}

 In the problem above the vote share is the same as the sample mean:
\begin{equation*}
\overline{X_i} = \frac{M}{N} =  \frac{1}{N}\sum_{i=1}^NX_i
\end{equation*}
You should be able to see that $E[\phi] = q$. What about the variance? 
 \begin{equation*}
{\rm var}(\phi) = {\rm var}(Y/N) = \frac{1}{N^2}{\rm var}(Y) = \frac{q(1-q)}{N}
 \end{equation*}
 Notice that this will tend towards zero as $N \to \infty$. Meanwhile, $E[\phi]$ has no dependence on $N$. This is a consequence of the fact that the CV is decreasing with $N$ and it allows us to determine $q$ by approximating $E[\phi]$ with the sample mean.








 \section{Connecting ``math world'' and ``data world'': LLN and CLT}\label{sec:llnclt}
 The goal of this section is to understand the distribution of a sum of iid random variables when $N$ is large. This is obviously relevant if we want to be more precise about how accurate our estimates are. We begin with the law of large numbers, which simply makes Eq. \ref{eq:EappoverY} -- the statement that the sample average approximates the expectation -- precise. 
 
 \subsection{LLN}
The binomial distribution illustrates a very basically principle that we have already used a number of times: When we sum over a large number of independent random variables and divide by the total number, the result is close to the mean. This is the Law of Large Numbers (LLN). 
 \begin{thm}[Law of Large numbers] Let $X_i$ be independent and identically distributed and set
 \begin{equation*}
 S_N = \sum_{i=1}^N X_i.
 \end{equation*}
 If $E[X_i]<\infty$, then $S_N/N \to E[X_i]$. 
 \end{thm}
 This is not very precise, since we should really be specific about what it means for a random number to converge to something, but for our purposes it will suffice to think of this as saying that for large enough $N$, $S_N/N$ will not differ from $E[X_i]$ very much. See  \cite[Theorem 4.2.1]{evans} for a more technical statement. Another way to say this is that for iid random variables $X_i$, $i=1,\dots,N$, the sample average $\overline{X}$ approach $E[X_i]$. 
The binomial distribution actually tell us more, it tell us that the variation around $E[X_i]$ is proportional to $1/\sqrt{N}$. It is natural to ask whether this is also true for other random variables. The key is that the dependence on $N$ in Equations \ref{eq:binomial_meanvar} does not depend on the distribution of $X_i$! So if $X_i$ is the roll of a dice, or a geometric distribution, we expect the same thing to hold. 
%  \begin{thm}[prerequisite to CLT] Let $X_i$ be independent and identically distributed with $E[X_i] = \mu_x<\infty$ and ${\rm var}(X_i) = \sigma_x^2<\infty$ $\sqrt{{\rm var}(S_N/N) }= \sigma_x/\sqrt{N}$. 
% \end{thm}
The behavior of random sums is in-fact even more universal than this argument suggests. We can actually describe the distribution of any\footnote{With the caveat that here we only deal with the case where ${\rm var}(X_i)<\infty$} random sum with a single distribution.  In order to describe this distribution, we need to introduce the notion of continuous random variables. 

 \subsection{Continuous probability distributions}
To understand what happens to the distribution of sums and averages of random variables, we need to extend our framework to \emph{continuous probability distributions}. The motivation comes from the sample average of many i.i.d.\ random variables,  
\[
\overline{Y} = \frac{1}{n}\sum_{i=1}^n Y_i.
\]  
Even if each \(Y_i\) only takes finitely many values (for instance, a Bernoulli random variable), the average can take increasingly many distinct values as \(n\) grows.  

For example, starting with iid Bernoulli variables $X_1,\dots,X_n$, the sample average $\bar{X}$ (which is a Binomial random variable divided by $n$)  has sample space 
\[
S_{\bar{X}} = \Bigl\{0,\tfrac{1}{n},\tfrac{2}{n},\dots,1\Bigr\}.
\]  
As \(n \to \infty\), this set of possible outcomes becomes dense in the interval \([0,1]\). In the limit we naturally want to talk about a probability distribution supported on a continuum of values---but our previous discrete framework does not cover this situation.  

Fortunately, much of the discrete theory still applies once we replace sums with integrals. You will not be asked to evaluate integrals in this course, but we need to set up the basic definitions.  



\subsubsection*{The Uniform Distribution}

A simple starting point is the \emph{uniform distribution} on an interval:  
\[
Y \sim \text{Uniform}(a,b).
\]  
Here \(Y\) is equally likely to fall anywhere in the interval \([a,b]\) (with \(a<b\)). If we let \(L = b-a\), then for any subinterval \(y_1 < y_2\) inside \([a,b]\),  
\[
P(y_1 \le Y \le y_2) = \frac{y_2-y_1}{L}.
\]  
This is shown in Figure \ref{fig:density}. 
In words: the probability of landing in an interval is proportional to its length. This ensures normalization:  
\[
P(a \le Y \le b) = 1.
\]  
Notice that as \(y_2 \to y_1\), the probability goes to zero. Thus \(P(Y=y)=0\) for any specific \(y\). This reflects the fact that there are uncountably many possible outcomes in any interval, so no single point can carry positive probability.  



\subsubsection*{Densities}

This example motivates the general notion of a \emph{probability density function} (pdf). A continuous random variable \(Y\) is characterized by a nonnegative function \(f(y)\), called its density, such that for any \(a<b\),  
\[
P(a < Y < b) = \int_a^b f(y)\,dy.
\]  
Geometrically, the probability is given by the \emph{area under the curve} of \(f(y)\) between \(a\) and \(b\).  

For small intervals,  
\[
P(y \le Y \le y+dy) \approx f(y)\,dy,
\]  
so \(f(y)\) plays the role of ``probability per unit length.''  

In the uniform case,  
\[
f(y) = 
\begin{cases}
1/L, & y \in [a,b], \\
0, & \text{otherwise}.
\end{cases}
\]  

Every pdf \(f(y)\) must satisfy:  
\begin{enumerate}
\item \textbf{Nonnegativity:} \(f(y) \ge 0\) for all \(y\).  
\item \textbf{Normalization:} \(\int_{-\infty}^{\infty} f(y)\,dy = 1\).  
\end{enumerate}

These are the continuous analogues of the conditions we imposed on discrete probability distributions.  Note that $f(y)$ need NOT be less than $1$, because $f(y)$ is not a probability, rather integrals $\int_{a}^bf(y)dy$ is a probability. For example, suppose $f(y)$ is a uniform distribution on $[0,L] = [0,1/1000]$. Then $f(y) = 1/L = 1000$ for $y$ between $0$ and $1/1000$, and zero otherwise. The fact that the density is concentrated in a very small region cancels with the large values it takes in this region so that the integrals are always $\le 1$.

For a density, the expectation is defined by replacing the sum with a integral: 
\begin{equation}
E[g(Y)] = \int_{S_Y}g(y)f(y)dy
\end{equation}
You won't have to calculate integrals in this class, but it's important to understand where the expectation comes from for a continuous distribution. 

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{./../figures/density}
\caption{The density and its relationship to probabilities}\label{fig:density}
\end{figure}



\begin{example}[Condition with continuous random variables]
If $Y$ is uniform on $[0,1]$. \\


\noindent
\underline{Question:}  What is the density of $Y|(Y<1/2)$? Check the answer with simulations.\\

 \noindent
\underline{Solution:} We can start with the definition of density
\begin{align*}
P(y_1<Y<y_2|Y<1/2) &= \frac{P(y_1<Y<y_2,Y<1/2)}{P(Y<1/2)}
\end{align*}
What is the think on the top? We will assume $y_1>0$ and $y_2<1/2$, then the numerator is $y_2-y_1$, since $Y<1/2$. The key here is that if $Y \in [y_1,y_2]$ $Y<1/2$ is automatically true, so the chance that BOTH of these things are true in a sample is the chance that the more restrictive one is true.

The denominator is $P(Y<1/2) = 1/2$. This means
\begin{equation*}
P(y_1<Y<y_2|Y<1/2) = 2(y_2-y_1)
\end{equation*}
This means the density is
\begin{equation*}
f(y|Y<1/2) = 2
\end{equation*}
Thus
\begin{equation*}
Y|(Y<1/2) \sim {\rm Uniform}(0,1/2)
\end{equation*}


\begin{lstlisting}[language=Python]
import numpy as np
import matplotlib.pyplot as plt

rng = np.random.default_rng(123)

# Number of samples
N = 200_000

# Sample Y ~ Uniform(0,1)
Y = rng.uniform(0, 1, size=N)

# Condition on Y < 1/2
Y_cond = Y[Y < 0.5]

print(f"Proportion of samples kept (should be ~0.5): {len(Y_cond)/N:.3f}")
print(f"Sample mean of conditional distribution: {Y_cond.mean():.3f}")
print(f"Theoretical mean of Uniform(0,0.5): {0.25}")

# Plot histogram of conditional samples
plt.figure(figsize=(6,4))
plt.hist(Y_cond, bins=40, density=True, alpha=0.7, label="Simulated density")
plt.axhline(2.0, color="red", linestyle="--", label="Theoretical density f(y|Y<1/2)=2")
plt.xlabel("y")
plt.ylabel("Density")
plt.title("Conditional distribution of Y given Y < 1/2")
plt.legend()
plt.tight_layout()
plt.show()
\end{lstlisting}

\end{example}


  \subsection{The Gaussian curve}
We know meet the most important probability model of all. This is the Normal distribution, which has a density 
   \begin{equation}\label{eq:normalpdf}
   g(x)= \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2 \sigma^2}}
   \end{equation}
 Despite the simplicity of the density function, calculating probabilities for Normal random variable by computing the area under the curve (integrating) is difficult. Instead we can remember some rough estimates based on the following figure. You should also be able to justify (to yourself) the bell curve shape by looking at the function. Hint: near $x = \mu$, the tangent line to $(x-\mu)^2$ is horizontal, then it decays exponentially. There is an inflection point, where is it? 

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{./../figures/bellcurve}
\caption{Probabilities in the Normal distribution}\label{fig:bellcurve}
\end{figure}

If $X$ has the probability density $g(x)$ given in Eq. \ref{eq:normalpdf}, then we write
\begin{equation}
X \sim {\rm Normal}(\mu, \sigma^2)
\end{equation}
It can be shown that $E[X] = \mu$ and ${\rm var}(X) = \sigma^2$, hence the Normal distribution has the mean and variance. But BE CAREFUL: Sometimes (in code or in math) normal random variables are parameterized by the mean and variance, so one would instead write ${\rm Normal}(\mu, \sigma)$. Both conventions are used, so always check. 





\begin{example}[Calculating probabilities for Normal distribution]
 We use the curve above to calculate probabilities of events in the Normal distribution. Suppose
\begin{equation*}
Y \sim {\rm Normal}(5,4)\\
\end{equation*}


 \noindent
\underline{Question:} What is (approximately) $P(Y > 7)$? \\

 \noindent
\underline{Solution:} Note that $5 + 2 =  7$, so this is asking how likely it is that a Normal variable is greater than $1$ standard deviation above the mean. This about $13.5+2 = 15.5\%$. We can always easily compute these probabilities in python as well.\\ 



 \noindent
\underline{Question:} What is
\begin{equation*}
P(Y>3|Y<7)?
\end{equation*}

 \noindent
\underline{Solution:} In this case we would use
\begin{equation*}
P(Y>3|Y<7) = \frac{P(Y>3,Y<7)}{P(Y<7)} 
\end{equation*}
Notice that $3 = 5-2 = \mu-\sigma$ and we already saw $7 = 5+2 = \mu+\sigma$, so $P(Y<7) \approx 0.839$ and $P(Y>3,Y<7) \approx 0.682$, thus the result is about $0.81$. 



\end{example}



  
  \subsection{The central limit theorem and sample distribution}
  
  
 We now have the formalism in place to state the Central Limit Theorem (CLT) in more precise terms. 
 \begin{thm} Let $X_i$ be a sequence of iid random variables and let 
 \begin{equation*}
E[X_i] = \mu,\quad  {\rm var}(X_i) = \sigma^2
 \end{equation*}
  and set 
  \begin{equation*}
 S_N = \sum_{i=1}^N X_i.
 \end{equation*}
 Then 
 \begin{equation}\label{eq:clt}
P\left( \frac{S_N-N\mu}{\sqrt{N \sigma^2}}<z\right) \to P(Z<z) 
 \end{equation}
Where
\begin{equation*}
Z \sim {\rm Normal}(0,1)
\end{equation*}
 \end{thm}
 The normal variable $Z$ with zero mean and variance one is called a \dfn{standard normal} random variable. Since evaluations of the CDF of a standard normal random variable appear so often, we use the shorthand 
 \begin{equation*}
 \Phi(z) = P(Z<z)
 \end{equation*}
 and write $\phi(z)$ for the pdf. 

 
\begin{example}[Binomial] Let 
\begin{equation*}
Y \sim {\rm Binomial}(N,q)
\end{equation*}


 \noindent
\underline{Question:} Assume $N$ is even and use the central limit theorem to approximate $P(Y<N/2)$ with a Normal distribution. How does the accuracy depend on $N$ and $q$? \\

 \noindent
\underline{Solution:} Using that $\mu = E[X_i] = q$ and $\sigma^2 = {\rm var}(X_i) = q(1-q)$, we find that the normal approximation to $Y$ is 
\begin{equation*}
P\left( \frac{Y - Nq}{\sqrt{N \sigma^2}} <z\right) \to P(Z<z)
\end{equation*}
for 
\begin{equation*}
Z \sim {\rm Normal}(0,1). 
\end{equation*}

Now we write
\begin{align*}
P\left( Y<N/2\right) &= P\left(Y - Nq <N/2-Nq\right) \\
&= P\left(\frac{Y - Nq}{\sqrt{N q(1-q)}} <\frac{N/2-Nq}{\sqrt{N q(1-q)}}\right)\\
&= P\left(\frac{Y - Nq}{\sqrt{N q(1-q)}} < \sqrt{N} \frac{1-2q}{2\sqrt{q(1-q)}}\right)\\
&\to P\left(Z < \sqrt{N} \frac{1-2q}{2\sqrt{q(1-q)}}\right) = \Phi\left( \sqrt{N} \frac{1-2q}{2\sqrt{q(1-q)}}\right)
\end{align*}
We can compute this in Python, both by generating samples and using the CDF function.  

\begin{lstlisting}[language=Python]
import numpy as np
from scipy.stats import norm, binom

# parameters
N, q = 200, 0.3
trials = 100000

# exact probability via binomial CDF
exact = binom.cdf(N//2 - 1, N, q)

# CLT approximation using Normal CDF (no continuity correction)
z = np.sqrt(N) * (1 - 2*q) / (2 * np.sqrt(q * (1 - q)))
clt_approx = norm.cdf(z)

# Monte Carlo estimate
samples = np.random.binomial(N, q, size=trials)
mc_estimate = np.mean(samples < N/2)

print(f"Exact:       {exact:.4f}")
print(f"CLT approx:  {clt_approx:.4f}")
print(f"Monte Carlo: {mc_estimate:.4f}")
\end{lstlisting}


\end{example}



 {\bf Note on iid assumption:} One of the most important things to recognize about the CLT when it comes to application is that the assumptions that the $X_i$ are independent are not that important, so long as they are not too correlated. Even though the precise quantitive statement of the CLT won't when there are correlations, the sum will still be well approximated by a Normal distribution. 






\subsection{Properties of Normal random variables}

 {\bf Linear transformations of Normal random variables:}  Suppose 
\begin{equation*}
Z \sim {\rm Normal}(0,1)
\end{equation*}
and define 
\begin{equation}\label{eq:Zlineartrans}
X = \sigma Z + \mu 
\end{equation}
Then 
\begin{align*}
P(X<x) &= P(\mu + \sigma Z<x) = P\left(Z<\frac{x - \mu}{\sigma}\right)\\
&= \int_{-\infty}^{\frac{x - \mu}{\sigma}}\phi(z)dz
\end{align*}
\noindent
Now set
\[
u = \mu + \sigma z \implies dz = \frac{du}{\sigma}.
\]

\noindent
When $z \to -\infty$, we have $u \to -\infty$, and when 
$z = \frac{x-\mu}{\sigma}$, we have $u = x$. Therefore,
\begin{align*}
P(X<x) 
&= \int_{-\infty}^{x} 
\phi\!\left(\frac{u-\mu}{\sigma}\right)\,\frac{1}{\sigma}\,du \\
&= \int_{-\infty}^{x} 
\frac{1}{\sigma\sqrt{2\pi}}
\exp\!\left(-\frac{(u-\mu)^2}{2\sigma^2}\right)\,du.
\end{align*}
We have shown that 
\begin{equation*}
X \sim {\rm Normal}(\mu,\sigma^2).
\end{equation*} 
when $X$ is given by Eq. \ref{eq:Zlineartrans}. In particular, any Normal random variable is obtained via a linear transformation of a standard normal. 



With this understanding of how to linearly transform a Normal random variable, we can see that the CLT can be informally stated as
\begin{equation*}
S_N \approx S_{\rm CLT} \sim {\rm Normal}(N\mu,N\sigma^2)
\end{equation*}
 More generally, 
\begin{equation*}
X \sim {\rm Normal}(\mu_x,\sigma_x)
\end{equation*}
Now consider 
\begin{equation*}\label{eq:linear}
Y = aX + b 
\end{equation*}
At this point it should make sense that $Y$ is also normal.  Taking the average of both sides, 
\begin{equation*}
E[Y] = a\mu + b
\end{equation*}
and 
\begin{equation*}
{\rm var}(Y) = {\rm var}(aX) + {\rm var}(b)
\end{equation*}
Form the formula for variance, we know ${\rm var}(aX)  = a^2{\rm var}(X)$. Also, ${\rm var}(b) =0$
So 
\begin{equation*}\label{eq:normal_linear_trans}
Y \sim {\rm Normal}(a\mu_x + b,a^2\sigma_x^2).
\end{equation*}
Note that in going from $Z$ to $X$ and $X$ to $Y$, we are just multiplying and shifting everything.
Think about what this does to the histogram. 
 The process of going from $X$ to $Z$ is called standardizing. For any variable $X$ the \dfn{standardized} variable is defined as 
\begin{equation*}
Z = \frac{X-\mu_x}{\sigma_x}
\end{equation*}
 {\bf Transforming $X$ to a standard Normal is equivalent to measuring $X$ in units of standard deviations.} For example, if we make a histogram of $X$, all this transformation does is change the $X$ axis to units of standard deviations from the mean. 

  \begin{thm}[Special case of Theorem 4.6.1 in \cite{evans}]\label{thm:addingnormal}
Let
\begin{align*}
X_1 &\sim {\rm Normal}(\mu_1,\sigma_1^2)\\
X_2 &\sim {\rm Normal}(\mu_2,\sigma_2^2)
\end{align*}
be independent, then 
\begin{equation*}
aX_1+bX_2 + d \sim {\rm Normal}\left(a\mu_1+b\mu_2+d,a^2\sigma_1^2 + b^2\sigma_2^2\right)
\end{equation*}
 \end{thm}

 \section{Examples of linear regression models}
Equipped with the normal distribution and it properties, we can begin to explore linear regression models, but we focus on properties of the model at the moment and not statistical inference aspect until the next unit. A (single-predictor) \dfn{linear regression model} is a model of the form 
\begin{equation}
Y|X \sim {\rm Normal}(\beta_0 + \beta_1 X,\sigma^2). 
\end{equation}
here $X$ is a called a \dfn{predictor} and $Y$ is the \dfn{response variable}. We begin with some examples. 

 

 \begin{example}[Linear regression with a binary predictor: the difference of means]\label{ex:zerothreg}
 Let
\begin{align*}
X &\sim {\rm Bernoulli}(1/2)\\
Y|X &\sim {\rm Normal}(\beta_1X + \beta_0,\sigma^2)
\end{align*}
 We motivate this by the following: A clinical trial is conducted where participants are placed in control ($X=0$) or treatment ($X=1$) groups. People in the treatment group recieve a drug some test outputs an observation $Y$ (such as blood pressure).

 \noindent
\underline{Question:} What is the marginal mean of $Y$? How would you estimate $\beta_1$? (not using least squares if you know it)  \\


 \noindent
\underline{Solution:} 
Another way to write the model is 
\begin{equation}
Y = \beta_1X + \beta_0 + \sigma Z
\end{equation}
and taking the expectation gives
\begin{equation}
E[Y] = \beta_1/2 + \beta_0
\end{equation}

The quantity of interest is usually $\beta_1$, which can be expressed as the difference between conditional expectations:
\begin{equation}
E[Y|X=1] - E[Y|X=0] = \beta_1
\end{equation}
Suppose we have $N$ data points $(X_1,Y_1),\dots,(X_N,Y_N)$.
Because we can compute expectations from sample averages, it is natural to estimate $\beta_1$ with a quantity $\hat{\beta}_1$ given by
\begin{equation}
\widehat{\beta}_1 =\overline{Y|X=1} - \overline{Y|X=0}
\end{equation}
where $\overline{Y|X=1}$ and $\overline{Y|X=0}$ are the conditional sample averages; that is,
\begin{equation}
 \overline{Y|X=1} = \frac{1}{N(X=1)}\sum_{i=1}^N Y_i1_{X_i=1}
 \end{equation}


Below I have functions which generate samples and produce an estimate of $\beta$


\begin{lstlisting}[language=Python]
def generate_data(beta0,beta1,sigma,n_samples):
  x = np.random.choice([0,1],n_samples)
  y = beta0 + beta1*x + np.random.normal(0,sigma,n_samples)
  # put in dataframe
  df = pd.DataFrame(np.array([x,y]).T,columns=['x','y'])
  return df

def beta1_hat(df):
  n_samples = df.shape[0]
  beta1_hat = (df[df['x']==1]['y'].mean()-df[df['x']==0]['y'].mean())
  return beta1_hat
\end{lstlisting}


This is a random quantity which depends on the number of samples we have and specific data we collected. A natural question to ask is: how many samples we need to have a high probability of being close to the true $\beta$? Specifically: 

\noindent
\underline{Question:} How large does $N$ need to be for the probability that $|\hat{\beta}_1 - \beta|<0.1$ to be at least $95$ percent?. \\


 \noindent
\underline{Solution:} 


The answer will depend on the parameter values so we will assume we have some rough idea of what these numbers might be. We can answer the question with simulations, but let's first obtain some analytical results. To make the calculation simpler, we assume there are exactly $N/2$ individuals in each group. This makes sense since for large enough $N$ there are very close to $N/2$ in each group:
\begin{equation}
N(X=0) \approx  N(X=1) \approx N/2
\end{equation}

Given our assumption about $N$, $\overline{Y|X=0}$ and $\overline{Y|X=1}$ are each sums of $N/2$ Normal random variables.
\begin{align}
\overline{Y|X=0} &\sim {\rm Normal}(\beta_0,\sigma^2/N)\\
\overline{Y|X=1} &\sim {\rm Normal}(\beta_0+\beta_1,\sigma^2/N)
\end{align}
Thus
\begin{equation}
\widehat{\beta}_1 \sim {\rm Normal}(\beta_1,2\sigma^2/N)
\end{equation}
Let's test this

\begin{lstlisting}[language=Python]
beta1_hat_dist = np.array([beta1_hat(generate_data(beta0,beta1,sigma,N)) for i in range(1000)])
# check normal probailities:
diff = np.abs(beta1_hat_dist - beta1)
len(diff[diff < 2*np.sqrt(2*sigma/N)])/len(diff)
\end{lstlisting}




We have confirmed that 
\begin{equation}
P(|\hat{\beta}_1 - \beta|_1<2{\rm se}(\widehat{\beta}_1)) \approx 0.95 
\end{equation}
as expected. 

If we want enough samples so that 
\begin{equation}
P(|\hat{\beta}_1 - \beta|_1<0.1) \approx 0.95
\end{equation}
then we should try to find $N$ so that 
\begin{equation}
2{\rm se}(\widehat{\beta}_1) = 4 \sigma/\sqrt{N} = 0.1
\end{equation}
This means we want 
\begin{equation}
N > 16\sigma^2/0.1^2
\end{equation}

\begin{lstlisting}[language=Python]
nc =16*sigma**2/0.1**2

n_range = np.array(range(2,25,1)) 
n_sims = 100 
p_within_01 = np.zeros(len(n_range)) # initialize array to store results
for i in range(len(n_range)):
  n = n_range[i]
  for j in range(n_sims):
    df = generate_data(beta0,beta1,sigma,n)
    b = beta1_hat(df)
    p_within_01[i] = p_within_01[i] + int(np.abs(b-beta1)<0.1)
p_within_01 = p_within_01/n_sims

fig,ax = plt.subplots(figsize=(10,4))
ax.plot(n_range,p_within_01,".")
ax.plot(n_range,np.ones(len(n_range))*0.95,"k--")
# verticle line at nc
ax.axvline(nc,color="red")
ax.set_xlabel("Number of samples")
ax.set_ylim([0,1])
\end{lstlisting}

 \end{example}

 
 \begin{example}[Linear regression model with Normal predictor]\label{ex:firstreg}
Let
\begin{align*}
X &\sim {\rm Normal}(\mu_x,\sigma_x^2)\\
Y|X &\sim {\rm Normal}(\beta_1X + \beta_0,\sigma^2)
\end{align*}

 \noindent
\underline{Question:} What is the marginal distribution of $Y$? What is $E[XY]$? How does this compare to $E[X]E[Y]$?\\


 \noindent
\underline{Solution:} We know that 
\begin{equation*}
Y|X =\beta_1X+\beta_0 + Z,\quad Z \sim {\rm Normal}(0,\sigma^2)
\end{equation*}
Thus, the marginal distribution of $Y$ is the sum of two Normal random variables with mean and variance $(\beta_1\mu_x+\beta_0,a\sigma_x^2)$ and $(0,\sigma^2)$ respectively. As we saw in the previous unit
\begin{equation*}
Y  \sim {\rm Normal}(\beta_1\mu_x+\beta_0,\beta_1^2\sigma_x^2 + \sigma^2)
\end{equation*}

To compute $E[XY]$, we note that 
\begin{equation*}
E[XY|X=x]=  E[xY|X=x]= xE[Y|X=x]
\end{equation*}
therefore
\begin{equation*}
E[XY] = E[XE[Y|X]] = E[X(\beta_1X+\beta_0)] = \beta_1E[X^2]+\beta_0E[X]
\end{equation*}
Using 
\begin{equation*}
E[X^2] = {\rm var}(X) + E[X]^2 = \sigma_x^2 + \mu_x^2
\end{equation*}
Therefore 
\begin{equation*}
E[XY] =  \beta_1\sigma_x^2 + \beta_1\mu_x^2 + \beta_0\mu_x
\end{equation*}
On the other hand, 
\begin{equation*}
E[X]E[Y] = \mu_x(\beta_1\mu_x+\beta_0) = \beta_1 \mu_x^2 +\beta_0 \mu_x
\end{equation*}
The difference between the two is the additional term $\beta_1\sigma_x^2$, which we picked up from the variance of $x$.  





\end{example}

\appendix

 \section{Additional discussion of continuous random variables (optional)}


\subsection{Exponential distribution}
 Suppose we want to model that time before a component of a machine fails. We will assume that the rate of failure -- that is, the chance that it fails per unit time -- is a constant $\lambda$. In other words, for a small time interval $dt$, the probability for the component to fail in a small time interval $[t,t+dt)$ given that it has not yet failed is $\lambda dt$. Or, in mathematical notation 
 If $T$ is the time of failure, then the density of $f_T(t)$ is 
\begin{equation*}
f_T(t) = \lambda e^{-\lambda t}.
\end{equation*}
$T$ is an \dfn{exponentially distributed} random variable, and we write
\begin{equation*}
T \sim {\rm Exponential}(\lambda).
\end{equation*}
An exponential variable has mean $E[T] = 1/\lambda$ and variance ${\rm var}(T) = 1/\lambda^2$. 



\begin{example}[Heterogeneous failure rate]

Suppose that the machine is defective with probability $0.1$. We can introduce a variable $X$ which indicates whether the machine is defective and will fail with a rate $10$. In other words, our model is 
\begin{align*}
X &\sim {\rm Bernoulli}(0.1)\\
T|(X=x) &\sim {\rm Exponential}(x10 + (1-x))
\end{align*}


\noindent
\underline{Question:} What is $E[T]$? What about ${\rm var}(T)$? Does $T$ follow an exponential distribution?\\ 


\noindent
\underline{Solution:} Using the tower property of expectation
\begin{align*}
E[T] &= E[E[T|X]] \\
&= E[T|X=0]P(X=0) + E[T|X=1]P(X=1) \\
&= 1 \cdot (1-0.1) + \frac{0.1}{10} = 0.9+0.01 = 0.91
\end{align*}
The variance 
\begin{equation*}
{\rm var}(T) = E[T^2]-E[T]^2
\end{equation*}
and 
\begin{align*}
E[T^2] = E[E[T^2|X]]  = (1-0.1)\times E[T^2|X=0] + 0.1 \times E[T^2|X=1] 
%&= 1^2 \cdot (1-0.1) +\frac{0.1}{10^2}\\
%&= 0.9 + 0.001  = 0.901
\end{align*}
Note that, from the variance formula and the fact that $T$ is exponential,
\begin{equation*}
E[T^2|X=1]  = {\rm var}(T|X=1) + E[T|X=1]^2 = \frac{1}{10^2}  + \frac{1}{10^2} = \frac{2}{10^2}
\end{equation*}
Hence 
\begin{align*}
E[T^2] = E[E[T^2|X]]  = 0.9 \cdot 2 + 0.1 \cdot \frac{2}{10^2} = 1.802
\end{align*}


\begin{equation*}
{\rm var}(T) =  1.802 -  0.91^2 = 0.9739
\end{equation*}
If $T$ is exponential, then 
\begin{equation*}
\lambda = \frac{1}{E[T]}=\frac{1}{0.91}.
\end{equation*}
We know that ${\rm var}(T) = E[T]^2$ for an exponential distribution, but 
\begin{equation*}
 \frac{1}{\lambda^2} = 0.91^2 = 0.8281 \ne  0.9739= {\rm var}(T). 
\end{equation*}


\end{example}




  

 \subsection{Conditional probability and expectation with Continuous variables}

The definition of expected value can be generalized to continuous variables by replacing the sums with integrals. That is, for a variable $X$ with density $f_X$, we have 
 \begin{equation*}
 E[X] = \int x f_X(x)dx 
 \end{equation*}
Suppose $X$ and $Y$ are two variables on the sample spaces $S_X = S_Y = \reals$. Then we can define a joint density $f_{X,Y}(x,y)$. From this, we can compute things like 
 \begin{equation*}
P(X>x,Y>y) = \int_{x}^{\infty}\int_y^{\infty}f_{X,Y}(x,y)dxdy
 \end{equation*}
 If $X$ and $Y$ are independent, then $f_{X,Y}(x,y) = f_X(x)f_Y(y)$ and 
 \begin{align*}
P(X>x,Y>y) &= \int_{x}^{\infty}\int_y^{\infty}f_{X,Y}(x,y) dx dy\\
&=  \int_{x}^{\infty}f_X(x)dx\int_y^{\infty}f_Y(y)dy
 =P(X>x)P(Y>y)
 \end{align*}

  
  

\newpage

\section*{Exercises}

 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Computing conditional averages \ding{111}]
Suppose we have some data representing samples of a pair of random variables $(Y_1,Y_2)$: 
\begin{equation*}
\{(1,2),(1,2),(3,1),(1,4),(3,3),(2,2),(1,5)\}
\end{equation*}
Compute the following both by hand and with Python. 
\begin{enumerate}[label=(\alph*)]
\item $E[Y_1]$
\item $E[Y_1|Y_2=2]$
\item $E[Y_2|Y_1=1]$
\item $E[Y_2|Y_1>1]$
\end{enumerate}
\end{exercise}

\begin{exercise}[\ding{111}]
Do Exercises 3.1.3, 3.1.4, 3.1.10, 3.1.14  in  \cite{evans} and for each one check your answer using simulations. 
\end{exercise}

 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Independence and conditional expectation \ding{111}]
Let $X$ and $Y$ be two random variables with (discrete) sample spaces $S_X$ and $S_Y$.  (you can find these in the textbook, but give them a try yourself first). 
\begin{enumerate}[label=(\alph*)]
\item Show that if $X$ and $Y$ are independent $E[X|Y=y]=E[X]$ and $E[Y|X=x]=E[Y]$ for all $x \in S_X$ and $y \in S_Y$.  You may assume $S_X$ and $S_Y$ have a finite number of elements, e.g. $S_X = \{1,2,3,4\}$. 
\item Prove the tower property of expectation, which says that 
\begin{equation*}
E[X] = \sum_{y \in S_Y}E[X|Y=y]P(Y=y)
\end{equation*} 
This is sometimes stated as $E[X] = E[E[X|Y]]$ where the inner expectation is interpreted as a random variable depending on the value of $Y$. 
\item Show that if $X$ and $Y$ are independent, then 
\begin{equation*}
{\rm var}(X+Y) = {\rm var}(X) + {\rm var}(Y)
\end{equation*} 

%\item Similar to how we define conditional expectation, we can define the conditional variance
%\begin{equation*}
%{\rm var}(X|Y=y) = \sum_{x\in S_X}(x-\E[X|Y=y])^2P(X=x|Y=y)
%\end{equation*}
%In general, do you think that conditioning will make the variance greater or less than the original variance of $X$?  Try to come up with an answer based solely on the intuitive definition of variance and conditioning, rather than using formulas and theorems. Feel free to test your answer with math or simulations though. 
\end{enumerate}
\end{exercise}

%---------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Verifying variance formula for Bernoulli variable \ding{111}]
Using Python, verify the formula for the variance
\begin{equation*}
{\rm Var}(Y) = q(1-q)
\end{equation*}
This is a bit vague, but part of the exercise is to think about how you might justify this formula. In particular, what type of plot should you make? Use AI to help with coding if needed, but think about what you are trying to achieve first. 
\end{exercise}



%\begin{exercise}[A first taste of hypothesis testing]
%Last spring, $1425$ out of  $2748$ of student voted ``I have no confidence in President Beilock's leadership'', which comes out to $51.86\%$. 
% Let's try to understand if this small margin could be a reflection of randomness in who voted rather than a true reflection of the student body's preference. To answer this, we make the \emph{null hypothesis} that in reality exactly $1/2$ of the  $6300$ students at Dartmouth support the vote of no confidence. We can then view the $2748$ students who voted as random samples from this pool of students. Under the null hypothesis, how likely is the vote margin to be as large as it was in reality?  You may ignore the chance that we could in principle sample the same student twice and you can either use simulations or formulas. 
%\end{exercise}





\begin{exercise}[Conditioning with continuous variables \ding{111}] Let
\begin{align*}
Z_1 &\sim {\rm Normal}(0,1)\\
Z_2 &\sim {\rm Normal}(1,2)
\end{align*} 
Compute each of the following using Python
\begin{enumerate}[label=(\alph*)]
\item $P(Z_1 + Z_2>3)$
\item $P(Z_1 + Z_2>3|Z_1<-1)$
\item $P(Z_2Z_1>0|Z_1+Z_2<4)$
\end{enumerate}
\end{exercise}

\begin{exercise}[General linear transformation]
Suppose $X \sim {\rm Normal}(5,9)$. Define
Y = -2X + 7.
\begin{enumerate}[label=(\alph*)]
\item Find the distribution of $Y$ (mean and variance).
\item Estimate $P(Y > 0)$ by hand and check with simulations. 
\end{enumerate}
\end{exercise}




\begin{exercise}
Do Exercise  2.4.2 in  \cite{evans} using simulations. You can also check your answer using calculus if you wish. 
\end{exercise}

\begin{exercise}
The {\bf random walk} is a foundational model in nearly every area of science.  It describes the "motion" of a variable which moves randomly over time without any memory of its past. Einstein developed a theory of the motion of microscopic particles based on random walks and they have been used as rudimentary models of stock prices. 

We can define a random walk as follows. 
Let $X_0=0$ and define $X_k$ for $k=1,2,3,\dots$ by the recursive formula 
\begin{align}\label{eq:rw}
X_{k+1} = X_{k}  + \Delta(2U_k - 1)
\end{align}
where $\Delta$ is a constant and 
\begin{equation*}
U_k  \sim {\rm Bernoulli}(1/2)
\end{equation*}
are iid random variables. 


We can think of $X_k$ as the position of a person who is randomly walking with 50-50 chance of the moving to the left or right by $\Delta$ at each time-step. The entire sequence $X_0,X_1,X_2,\dots$ is referred to as the path of the random walker. 
\begin{enumerate}[label=(\alph*)]
\item Write a python function simulaterw(Delta,K) which simulates a random walk for $N$ steps. Yours code should return the entire path in a numpy array. Make some plots of $X_k$ vs. $k$. 
\item What are $E[X_k|X_{k-1}=2]$ and $E[X_k]$? 
%\item A much harder problem is to calculate $E[X_k|X_{k-1}>0]$. Don't calculate it, but explain why this is more difficult to calculate then the quantities above. 
\item Using the central limit theorem, derive an approximation of the {\bf mean squared displacement}
\begin{equation*}
{\rm MSD}(X_k) = E[X_k^2]
\end{equation*}
(you might notice this is just another name for the variance that is used in the context of random walks)
Verify your approximation by plotting ${\rm MSD}(X_k)$ as a function of $N$. 
\end{enumerate}



%You can start by modifying the following function:

\end{exercise}





 \bibliographystyle{cell}
\bibliography{./../refs.bib}

  
  \end{document}
 
 